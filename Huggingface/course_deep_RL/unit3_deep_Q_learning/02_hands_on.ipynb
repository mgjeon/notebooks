{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "062f446a-8673-4326-8319-b2035b98baaf",
   "metadata": {},
   "source": [
    "# Hands-on\n",
    "\n",
    "- https://huggingface.co/learn/deep-rl-course/unit3/hands-on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d70cfba-3c3b-4d59-b62d-166d4e99f1fb",
   "metadata": {},
   "source": [
    "### üéÆ Environments:\n",
    "\n",
    "- [SpacesInvadersNoFrameskip-v4](https://gymnasium.farama.org/environments/atari/space_invaders/)\n",
    "\n",
    "You can see the difference between Space Invaders versions here üëâ \n",
    "- https://gymnasium.farama.org/environments/atari/space_invaders/#variants\n",
    "- https://ale.farama.org/environments/space_invaders/\n",
    "\n",
    "### üìö RL-Library:\n",
    "\n",
    "- [RL-Baselines3-Zoo](https://github.com/DLR-RM/rl-baselines3-zoo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb806c52-fcb4-4f04-9f94-c3f11581f416",
   "metadata": {},
   "source": [
    "```\n",
    "pip install git+https://github.com/DLR-RM/rl-baselines3-zoo\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790e8548-6653-4553-8370-f2025faf0225",
   "metadata": {},
   "source": [
    "## Train our Deep Q-Learning Agent to Play Space Invaders üëæ\n",
    "\n",
    "To train an agent with RL-Baselines3-Zoo, we just need to do two things:\n",
    "\n",
    "1. Create a hyperparameter config file that will contain our training hyperparameters called `dqn.yml`.\n",
    "\n",
    "This is a template example:\n",
    "\n",
    "```\n",
    "SpaceInvadersNoFrameskip-v4:\n",
    "  env_wrapper:\n",
    "    - stable_baselines3.common.atari_wrappers.AtariWrapper\n",
    "  frame_stack: 4\n",
    "  policy: 'CnnPolicy'\n",
    "  n_timesteps: !!float 1e6\n",
    "  buffer_size: 100000\n",
    "  learning_rate: !!float 1e-4\n",
    "  batch_size: 32\n",
    "  learning_starts: 100000\n",
    "  target_update_interval: 1000\n",
    "  train_freq: 4\n",
    "  gradient_steps: 1\n",
    "  exploration_fraction: 0.1\n",
    "  exploration_final_eps: 0.01\n",
    "  # If True, you need to deactivate handle_timeout_termination\n",
    "  # in the replay_buffer_kwargs\n",
    "  optimize_memory_usage: False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3b0feb-d15b-49cb-be03-538466751dc9",
   "metadata": {},
   "source": [
    "Here we see that:\n",
    "- We use the `Atari Wrapper` that preprocess the input (Frame reduction ,grayscale, stack 4 frames)\n",
    "- We use `CnnPolicy`, since we use Convolutional layers to process the frames\n",
    "- We train it for 1 million `n_timesteps`\n",
    "- Memory (Experience Replay) size is 100000, aka the amount of experience steps you saved to train again your agent with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca963fd1-169a-44a7-bf9b-00db5e064397",
   "metadata": {},
   "source": [
    "In terms of hyperparameters optimization, my advice is to focus on these 3 hyperparameters:\n",
    "- `learning_rate`\n",
    "- `buffer_size (Experience Memory size)`\n",
    "- `batch_size`\n",
    "\n",
    "As a good practice, you need to **check the documentation to understand what each hyperparameters does**: https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html#parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f11657-7034-4d2e-a781-0a38cf61d825",
   "metadata": {},
   "source": [
    "2. We start the training and save the models on `logs` folder üìÅ\n",
    "\n",
    "- Define the algorithm after `--algo`, where we save the model after `-f` and where the hyperparameter config is after `-c`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acf7fdb-285e-4b3e-beb8-d942f4b36d53",
   "metadata": {},
   "source": [
    "```\n",
    "python -m rl_zoo3.train --algo dqn  --env SpaceInvadersNoFrameskip-v4 -f logs/ -c dqn.yml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff30d1d-7f60-4d4f-b863-451849a28f41",
   "metadata": {},
   "source": [
    "## Let's evaluate our agent üëÄ\n",
    "- RL-Baselines3-Zoo provides `enjoy.py`, a python script to evaluate our agent. In most RL libraries, we call the evaluation script `enjoy.py`.\n",
    "- Let's evaluate it for 5000 timesteps üî•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424e46cf-9f84-4487-9caf-5294c4ca8a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading latest experiment, id=1\n",
      "Loading logs/dqn/SpaceInvadersNoFrameskip-v4_1/SpaceInvadersNoFrameskip-v4.zip\n",
      "A.L.E: Arcade Learning Environment (version 0.10.1+unknown)\n",
      "[Powered by Stella]\n",
      "Stacking 4 frames\n",
      "Atari Episode Score: 315.00\n",
      "Atari Episode Length 2573\n",
      "Atari Episode Score: 605.00\n",
      "Atari Episode Length 4439\n",
      "Atari Episode Score: 800.00\n",
      "Atari Episode Length 4201\n",
      "Atari Episode Score: 575.00\n",
      "Atari Episode Length 4274\n"
     ]
    }
   ],
   "source": [
    "!python -m rl_zoo3.enjoy  --algo dqn  --env SpaceInvadersNoFrameskip-v4  --no-render  --n-timesteps 5000  --folder logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300702ff",
   "metadata": {},
   "source": [
    "### Record  a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15afa80-7edb-400c-bc0c-0430fdb41a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading latest experiment, id=1\n",
      "Loading logs/dqn/SpaceInvadersNoFrameskip-v4_1/SpaceInvadersNoFrameskip-v4.zip\n",
      "A.L.E: Arcade Learning Environment (version 0.10.1+unknown)\n",
      "[Powered by Stella]\n",
      "Stacking 4 frames\n",
      "Loading logs/dqn/SpaceInvadersNoFrameskip-v4_1/SpaceInvadersNoFrameskip-v4.zip\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Saving video to /home/mgj/wsl/notebooks/Huggingface/course_deep_RL/unit3_deep_Q_learning/logs/dqn/SpaceInvadersNoFrameskip-v4_1/videos/final-model-dqn-SpaceInvadersNoFrameskip-v4-step-0-to-step-1000.mp4\n",
      "MoviePy - Building video /home/mgj/wsl/notebooks/Huggingface/course_deep_RL/unit3_deep_Q_learning/logs/dqn/SpaceInvadersNoFrameskip-v4_1/videos/final-model-dqn-SpaceInvadersNoFrameskip-v4-step-0-to-step-1000.mp4.\n",
      "MoviePy - Writing video /home/mgj/wsl/notebooks/Huggingface/course_deep_RL/unit3_deep_Q_learning/logs/dqn/SpaceInvadersNoFrameskip-v4_1/videos/final-model-dqn-SpaceInvadersNoFrameskip-v4-step-0-to-step-1000.mp4\n",
      "\n",
      "MoviePy - Done !                                                                \n",
      "MoviePy - video ready /home/mgj/wsl/notebooks/Huggingface/course_deep_RL/unit3_deep_Q_learning/logs/dqn/SpaceInvadersNoFrameskip-v4_1/videos/final-model-dqn-SpaceInvadersNoFrameskip-v4-step-0-to-step-1000.mp4\n"
     ]
    }
   ],
   "source": [
    "!python -m rl_zoo3.record_video --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -n 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ca64e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
