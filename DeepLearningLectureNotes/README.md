# Deep Learning Lecture at Kyung Hee University (KHU)

# References

## General
- [Understanding Deep Learning](https://udlbook.github.io/udlbook/)
- [Probabilistic Machine Learning](https://probml.github.io/pml-book/)
- [Dive into Deep Learning](https://d2l.ai/)
- [Deep Learning](https://www.deeplearningbook.org/)
- [UvA Deep Learning Tutorials](https://uvadlc-notebooks.readthedocs.io/en/latest/index.html#)
- [Deep Learning Fundamentals](https://lightning.ai/courses/deep-learning-fundamentals/)
- [Practical Deep Learning](https://course.fast.ai/)

## Entropy
- [Concepts in Thermal Physics](https://www.amazon.com/Concepts-Thermal-Physics-Stephen-Blundell/dp/0199562105)
- [A Gentle Introduction to Cross-Entropy for Machine Learning](https://machinelearningmastery.com/cross-entropy-for-machine-learning/)
- [Entropy (for data science) Clearly Explained!!!](https://www.youtube.com/watch?v=YtebGVx-Fxw)
- [Neural Networks Part 6: Cross Entropy](https://www.youtube.com/watch?v=6ArSys5qHAU)
- [A Short Introduction to Entropy, Cross-Entropy and KL-Divergence](https://www.youtube.com/watch?v=ErfnhcEV1O8)
- [KL divergence](https://www.youtube.com/watch?v=SxGYPqCgJWM)
- [The KL Divergence : Data Science Basics](https://www.youtube.com/watch?v=q0AkK8aYbLY)

## Automatic Differentiation
- [Dive into Deep Learning; 2.5 Automatic Differentiation](https://d2l.ai/chapter_preliminaries/autograd.html)
- [Wikipedia; Automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation)
- [A Gentle Introduction to torch.autograd](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)
- [Automatic Differentiation with torch.autograd](https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html)
- [Of VJPs and JVPs](https://maximerobeyns.com/of_vjps_and_jvps)
- [The Autodiff Cookbook](https://jax.readthedocs.io/en/latest/notebooks/autodiff_cookbook.html)

## Optimization
- [Wikipedia; Optimization problem](https://en.wikipedia.org/wiki/Optimization_problem)
- [Wikipedia; Gradient descent](https://en.wikipedia.org/wiki/Gradient_descent)
- [Optimization and Convergence](https://physicsbaseddeeplearning.org/overview-optconv.html)

## Matrix Multiplication
- [Inside the Matrix: Visualizing Matrix Multiplication, Attention and Beyond](https://pytorch.org/blog/inside-the-matrix/)

## Matrix Calculus
- [Wikipedia; Layout conventions](https://en.wikipedia.org/wiki/Matrix_calculus#Layout_conventions)
- [Matrix Calculus for Machine Learning and Beyond](https://ocw.mit.edu/courses/18-s096-matrix-calculus-for-machine-learning-and-beyond-january-iap-2023/pages/syllabus/)
- [The Matrix Calculus You Need For Deep Learning](https://arxiv.org/abs/1802.01528)

## Logit
- [What is a Logit?](https://www.youtube.com/watch?v=8ZcccMzTz7Y)
- [Logistic vs Logit Functions](https://www.youtube.com/watch?v=YaQEUgIr4Mk)
- [Odds and Log(Odds), Clearly Explained!!!](https://www.youtube.com/watch?v=ARfXDSkQf1Y)